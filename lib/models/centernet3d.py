# import os
# import cv2
import torch
import torch.nn as nn
import numpy as np
import os
try:
    local_rank = int(os.environ["LOCAL_RANK"])
except:
    local_rank = -1

try:
    world_size = int(os.environ['WORLD_SIZE'])
except:
    world_size = -1

from loguru import logger
from lib.backbones import dla
from lib.backbones.dlaup import DLAUp
# from lib.backbones.hourglass import get_large_hourglass_net
# from lib.backbones.hourglass import load_pretrian_model
import lib.models.common as common

class CenterNet3D(nn.Module):
    def __init__(self, backbone='dla34', neck='DLAUp', num_class=3, downsample=4):
        """
        CenterNet for monocular 3D object detection.
        :param backbone: the backbone of pipeline, such as dla34.
        :param neck: the necks of detection, such as dla_up.
        :param downsample: the ratio of down sample. [4, 8, 16, 32]
        :param head_conv: the channels of convolution in head. default: 256
        """
        assert downsample in [4, 8, 16, 32]
        super().__init__()

        self.heads = {'heatmap': num_class, 
                        'offset_2d': 2, 
                        'size_2d':4,
                        'depth': 2, 
                        'offset_3d': 2, 
                        'size_3d':3, 
                        'heading': 24,
                        #'line_cls':22,
                        #'line_vis':1*6*5,
                        'line_reg':3*19*4, # xyz,anchor_x,anchor_y
                      }
        
        self.backbone = getattr(dla, backbone)(pretrained=True, return_levels=True)
        channels = self.backbone.channels  # channels list for feature maps generated by backbone
        self.first_level = int(np.log2(downsample))
        scales = [2 ** i for i in range(len(channels[self.first_level:]))]
        self.neck = DLAUp(channels[self.first_level:], scales_list=scales)   # feature fusion [such as DLAup, FPN]
        self.spp = common.ASPP(channels[self.first_level],channels[self.first_level])
        self.linear1=nn.Linear(1920,640)
        self.ac = nn.Hardswish()
        self.linear2=nn.Linear(640,456)
        self.norm = nn.BatchNorm1d(456)
        self.ac = nn.Hardswish()
        self.linear3=nn.Linear(456,3*19*4)
        
        # initialize the head of pipeline, according to heads setting.
        for head in self.heads.keys():
            output_channels = self.heads[head]
            # initialization
            if 'heatmap' in head:
                fc = nn.Sequential(
                    nn.Conv2d(channels[self.first_level], 256, kernel_size=3, padding=1, bias=True),
                    nn.SiLU(inplace=True),
                    nn.Conv2d(256, output_channels, kernel_size=1, stride=1, padding=0, bias=True))
                fc[-1].bias.data.fill_(-2.19)
            elif 'offset_2d' in head or 'size_2d' in head:
                fc = nn.Sequential(
                    nn.Conv2d(channels[self.first_level], 256, kernel_size=3, padding=1, bias=True),
                    nn.SiLU(inplace=True),
                    nn.Conv2d(256, output_channels, kernel_size=1, stride=1, padding=0, bias=True))
                fc.apply(weights_init_xavier)
            elif 'offset_3d' in head or 'size_3d' in head or 'heading' in head or 'depth' in head:
                fc = nn.Sequential(
                    nn.Conv2d(channels[self.first_level], 256, kernel_size=3, padding=1, bias=True),
                    nn.SiLU(inplace=True),
                    #nn.AdaptiveAvgPool2d(1), #BUG: kerneral size
                    nn.Conv2d(256, output_channels, kernel_size=1, stride=1, padding=0, bias=True))
                fc.apply(weights_init_xavier)
            elif 'line_cls' in head or 'line_reg' in head or 'line_vis' in head:
                fc = nn.Sequential(
                    nn.Conv2d(channels[self.first_level], 256, kernel_size=3, padding=1, bias=True),
                    nn.SiLU(inplace=True),
                    nn.AdaptiveAvgPool2d((24,80)),
                    nn.BatchNorm2d(256),
                    nn.Conv2d(256, 1, kernel_size=1, stride=1, padding=0, bias=True))
                fc.apply(weights_init_xavier)
            else:
                fc = nn.Sequential(
                    nn.Conv2d(channels[self.first_level], 256, kernel_size=3, padding=1, bias=True),
                    nn.SiLU(inplace=True),
                    nn.Conv2d(256, output_channels, kernel_size=1, stride=1, padding=0, bias=True))
                #self.fill_fc_weights(fc)
                fc.apply(weights_init_xavier)


            self.__setattr__(head, fc)
            if local_rank == 0:
                logger.debug(f'{head} init')

    # @torch.compile()
    def forward(self, input):
        feat = self.backbone(input)
        feat = self.neck(feat[self.first_level:])
        feat = self.spp(feat)

        ret = {}
        for head in self.heads:
            if head == 'line_reg':
                x = self.__getattr__(head)(feat)
                xx = x.view(x.size(0),-1)               
                x= self.linear1(xx)
                x= self.ac(x)
                x= self.linear2(x)
                x= self.norm(x)
                x= self.ac(x)
                x= self.linear3(x)
                ret[head]=x 
            else:
                ret[head] = self.__getattr__(head)(feat)

        return ret


    def fill_fc_weights(self, layers):
        for m in layers.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.normal_(m.weight, std=0.001)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

def weights_init_xavier(m):
    classname = m.__class__.__name__
    if classname.find('Linear') != -1:
        nn.init.xavier_uniform_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0.0)
    elif classname.find('Conv') != -1:
        nn.init.xavier_uniform_(m.weight)
        if m.bias is not None:
            nn.init.constant_(m.bias, 0.0)
    elif classname.find('BatchNorm') != -1:
        if m.affine:
            nn.init.constant_(m.weight, 1.0)
            nn.init.constant_(m.bias, 0.0)


if __name__ == '__main__':
    import torch
    net = CenterNet3D(backbone='dla34')
    print(net)

    input = torch.randn(4, 3, 384, 1280)
    print(input.shape, input.dtype)
    output = net(input)
    print(output.keys())


